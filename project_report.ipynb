{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation\n",
    "\n",
    "* Damilola Agbolabori\n",
    "* Obinna Onyema\n",
    "\n",
    "####  Emails:\n",
    "* dagbolabori@torontomu.ca\n",
    "* obinna.onyema@torontomu.ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "\n",
    "#### Problem Description:\n",
    "\n",
    "Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL tasks. However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions. To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborate their pros and cons.\n",
    "\n",
    "#### Context of the Problem:\n",
    "\n",
    "LLMs require \"coaching\" or prompts to condition them to generate the correct responses. Prompt engineering for SQL tasks is tricky because there's syntax and noise challenges that LLMs struggle with.\n",
    "\n",
    "#### Limitation About other Approaches:\n",
    "\n",
    "Write a sentence or two about limitations of prior appraoches (you will provide their details in the background section next)\n",
    "\n",
    "#### Solution:\n",
    "\n",
    "How the method you are discussing is going to solve it today. Wrtie couple of sentences only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Explain the related work using the following table\n",
    "\n",
    "| Reference |Explanation |  Dataset/Input |Weakness\n",
    "| --- | --- | --- | --- |\n",
    "| Yu et al. (2018) | They used a Seq2Seq model to create a tree based SQL decoder that can identify columns better as well as create nested queries| Spider dataset | Only 48% accuracy\n",
    "| Wang et al. (2020) | They focused on the medical domain considering the unique structure and terminology of medical records. They introduced the Translate-Edit Model for Question-to-SQL (TREQS) generation task by first generating the targeted SQL directly then editing with both attentive-copying mechanism and a recover technique| MIMICSQL | High accuracy of 85% but small dataset of 10k records\n",
    "\n",
    "\n",
    "The last row in this table should be about the method discussed in this paper (If you can't find the weakenss of this method then write about the future improvement, see the future work section of the paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "Provide details of the method that you are implementing in the next section with figure(s).  Your methodology will be just one method discussed in one of the paper of your choice; it can be a merger or a simplified version of the papers. To avoid any confusion, do not present multiple methods, just one unified method as you will implement in the next section.\n",
    "\n",
    "For figures you can use this tag:\n",
    "\n",
    "![Alternate text ](Figure.png \"Title of the figure, location is simply the directory of the notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "In this section, you will provide the code and its explanation. You may have to create more cells after this. (To keep the Notebook clean, do not display debugging output or thousands of print statements from hundreds of epochs. Make sure it is readable for others by reviewing it yourself carefully.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Future Direction\n",
    "\n",
    "Write what you have learnt in this project. In particular, write few sentences about the results and their limitations, how they can be extended in future. Make sure your own inference/learnings are depicted here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References:\n",
    "\n",
    "[1]:  Authors names, title of the paper, Conference Name,Year, page number (iff available)\n",
    "\n",
    "[2]:  Author names, title of the paper, Journal Name,Journal Vol, Issue Num, Year, page number (iff available)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
